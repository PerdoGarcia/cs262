import re
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import numpy as np
from collections import defaultdict
import os
import sys
import time

class LamportClockAnalyzer:
    """
    Analyzer for Lamport Clock logs generated by the distributed system simulation.
    """
    def __init__(self, log_files=None):
        """
        Initialize the analyzer with log files.

        Args:
            log_files (dict): Dictionary mapping machine IDs to log file paths
        """
        self.log_files = log_files or {}
        self.logs = {}  # Will hold parsed logs for each machine
        self.log_pattern = re.compile(
            r"System Time: (\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) \| \| \s*(\w+)\s* \| \| (.*?) \| \| Queue Size: (\d+) \| \| Logical Clock: (\d+)"
        )

    def add_log_file(self, machine_id, file_path):
        """Add a log file for a specific machine."""
        self.log_files[machine_id] = file_path

    def parse_logs(self):
        """Parse all log files and store structured data."""
        for machine_id, file_path in self.log_files.items():
            try:
                with open(file_path, 'r') as f:
                    log_content = f.read()
                self.logs[machine_id] = self._parse_log_content(log_content, machine_id)
                print(f"Parsed log for machine {machine_id}: {len(self.logs[machine_id])} events")
            except Exception as e:
                print(f"Error parsing log for machine {machine_id}: {e}")

        return self.logs

    def _parse_log_content(self, log_content, machine_id):
        """Parse the content of a log file into structured data."""
        events = []

        for line in log_content.strip().split('\n'):
            match = self.log_pattern.match(line)
            if match:
                timestamp_str, event_type, details, queue_size, logical_clock = match.groups()

                # Parse the timestamp
                timestamp = datetime.strptime(timestamp_str, "%Y-%m-%d %H:%M:%S")

                # Extract source machine for RECEIVE events
                source_machine = None
                if event_type.strip() == "RECEIVE":
                    receive_match = re.search(r"Receive machine (\d+)", details)
                    if receive_match:
                        source_machine = int(receive_match.group(1))

                # Extract target machine for SEND events
                target_machine = None
                if event_type.strip() == "SEND":
                    send_match = re.search(r"Sent to machine (\d+)", details)
                    if send_match:
                        target_machine = int(send_match.group(1))

                event = {
                    "machine_id": machine_id,
                    "timestamp": timestamp,
                    "event_type": event_type.strip(),
                    "details": details.strip(),
                    "queue_size": int(queue_size),
                    "logical_clock": int(logical_clock),
                    "source_machine": source_machine,
                    "target_machine": target_machine
                }

                events.append(event)

        # Convert to DataFrame for easier analysis
        df = pd.DataFrame(events)

        # Add seconds from start for relative time comparison
        if not df.empty:
            start_time = df["timestamp"].min()
            df["seconds_from_start"] = (df["timestamp"] - start_time).dt.total_seconds()

        return df

    def find_clock_jumps(self, threshold=1):
        """
        Find jumps in logical clocks where the difference is greater than the threshold.

        Args:
            threshold (int): The minimum jump size to consider

        Returns:
            dict: Dictionary of jumps by machine
        """
        jumps = {}

        for machine_id, log_df in self.logs.items():
            if log_df.empty:
                continue

            machine_jumps = []
            sorted_df = log_df.sort_values("timestamp")

            for i in range(1, len(sorted_df)):
                prev_row = sorted_df.iloc[i-1]
                curr_row = sorted_df.iloc[i]

                jump = curr_row["logical_clock"] - prev_row["logical_clock"]

                if jump > threshold:
                    machine_jumps.append({
                        "from_time": prev_row["timestamp"],
                        "to_time": curr_row["timestamp"],
                        "from_clock": prev_row["logical_clock"],
                        "to_clock": curr_row["logical_clock"],
                        "jump": jump,
                        "event_type": curr_row["event_type"]
                    })

            jumps[machine_id] = machine_jumps

        return jumps

    def compare_clock_rates(self):
        """
        Compare how quickly each machine's logical clock advances.

        Returns:
            dict: Clock rates and statistics for each machine
        """
        stats = {}

        for machine_id, log_df in self.logs.items():
            if log_df.empty:
                continue

            # Calculate total time span in seconds
            time_span = (log_df["timestamp"].max() - log_df["timestamp"].min()).total_seconds()

            # Calculate total clock advancement
            clock_range = log_df["logical_clock"].max() - log_df["logical_clock"].min()

            # Calculate clock rate (ticks per second)
            clock_rate = clock_range / time_span if time_span > 0 else 0

            stats[machine_id] = {
                "start_time": log_df["timestamp"].min(),
                "end_time": log_df["timestamp"].max(),
                "time_span_seconds": time_span,
                "start_clock": log_df["logical_clock"].min(),
                "end_clock": log_df["logical_clock"].max(),
                "clock_range": clock_range,
                "clock_rate": clock_rate
            }

        return stats

    def get_event_counts(self):
        """
        Count different event types for each machine.

        Returns:
            dict: Event counts by machine and type
        """
        event_counts = {}

        for machine_id, log_df in self.logs.items():
            if log_df.empty:
                continue

            # Count events by type
            counts = log_df["event_type"].value_counts().to_dict()

            # Calculate percentages
            total = sum(counts.values())
            percentages = {event: (count / total) * 100 for event, count in counts.items()}

            event_counts[machine_id] = {
                "counts": counts,
                "percentages": percentages,
                "total": total
            }

        return event_counts

    def analyze_queue_sizes(self):
        """
        Analyze queue sizes over time for each machine.

        Returns:
            dict: Queue size statistics by machine
        """
        queue_stats = {}

        for machine_id, log_df in self.logs.items():
            if log_df.empty:
                continue

            queue_stats[machine_id] = {
                "max": log_df["queue_size"].max(),
                "min": log_df["queue_size"].min(),
                "mean": log_df["queue_size"].mean(),
                "median": log_df["queue_size"].median(),
                "end_value": log_df.iloc[-1]["queue_size"] if not log_df.empty else None,
                "by_event_type": {
                    event_type: log_df[log_df["event_type"] == event_type]["queue_size"].mean()
                    for event_type in log_df["event_type"].unique()
                }
            }

        return queue_stats

    # def analyze_message_patterns(self):
    #     """
    #     Analyze message sending and receiving patterns between machines.

    #     Returns:
    #         dict: Message pattern statistics
    #     """
    #     patterns = {}

    #     # Count messages sent between each pair of machines
    #     message_matrix = np.zeros((3, 3))  # Assuming 3 machines

    #     for machine_id, log_df in self.logs.items():
    #         if log_df.empty:
    #             continue

    #         # Count outgoing messages
    #         send_events = log_df[log_df["event_type"] == "SEND"]
    #         for _, event in send_events.iterrows():
    #             if event["target_machine"] is not None:
    #                 message_matrix[machine_id][event["target_machine"]] += 1

    #         # Count incoming messages
    #         receive_events = log_df[log_df["event_type"] == "RECEIVE"]
    #         for _, event in receive_events.iterrows():
    #             if event["source_machine"] is not None:
    #                 message_matrix[event["source_machine"]][machine_id] += 1

    #     patterns["message_matrix"] = message_matrix

    #     # Calculate message delivery times (could be done if we had message IDs to match)
    #     # For now, we'll just count messages

    #     return patterns

    def analyze_temporal_correlation(self):
        """
        Analyze how events correlate across machines in time.

        Returns:
            dict: Temporal correlation statistics
        """
        correlations = {}

        # Combine all logs and sort by timestamp
        all_events = []
        for machine_id, log_df in self.logs.items():
            if log_df.empty:
                continue

            for _, event in log_df.iterrows():
                all_events.append(event)

        # Sort by timestamp
        all_events.sort(key=lambda event: event["timestamp"])

        # Analyze events happening within close time windows
        time_windows = {}
        for i, event in enumerate(all_events):
            # Create 1-second time windows
            window_key = event["timestamp"].strftime("%Y-%m-%d %H:%M:%S")
            if window_key not in time_windows:
                time_windows[window_key] = {0: 0, 1: 0, 2: 0}

            time_windows[window_key][event["machine_id"]] += 1

        correlations["time_windows"] = time_windows

        return correlations

    def plot_logical_clocks(self, save_path=None):
        """
        Plot logical clocks for all machines over time.

        Args:
            save_path (str, optional): Path to save the plot
        """
        plt.figure(figsize=(12, 8))

        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Blue, orange, green
        markers = ['o', 's', '^']  # Circle, square, triangle

        for i, (machine_id, log_df) in enumerate(self.logs.items()):
            if log_df.empty:
                continue

            plt.plot(log_df["seconds_from_start"], log_df["logical_clock"],
                     label=f"Machine {machine_id}",
                     color=colors[i % len(colors)],
                     marker=markers[i % len(markers)],
                     alpha=0.7,
                     markersize=4,
                     markevery=max(1, len(log_df) // 20))  # Show fewer markers for clarity

        plt.xlabel("Seconds from start")
        plt.ylabel("Logical Clock Value")
        plt.title("Logical Clock Progression Across Machines")
        plt.legend()
        plt.grid(True)

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
        else:
            plt.show()

    def plot_queue_sizes(self, save_path=None):
        """
        Plot queue sizes for all machines over time.

        Args:
            save_path (str, optional): Path to save the plot
        """
        plt.figure(figsize=(12, 8))

        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Blue, orange, green
        markers = ['o', 's', '^']  # Circle, square, triangle

        for i, (machine_id, log_df) in enumerate(self.logs.items()):
            if log_df.empty:
                continue

            plt.plot(log_df["seconds_from_start"], log_df["queue_size"],
                     label=f"Machine {machine_id}",
                     color=colors[i % len(colors)],
                     marker=markers[i % len(markers)],
                     alpha=0.7,
                     markersize=4,
                     markevery=max(1, len(log_df) // 20))  # Show fewer markers for clarity

        plt.xlabel("Seconds from start")
        plt.ylabel("Queue Size")
        plt.title("Queue Size Progression Across Machines")
        plt.legend()
        plt.grid(True)

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
        else:
            plt.show()

    def plot_event_distribution(self, save_path=None):
        """
        Plot distribution of event types for each machine.

        Args:
            save_path (str, optional): Path to save the plot
        """
        event_counts = self.get_event_counts()

        # Prepare data for plotting
        machines = list(event_counts.keys())
        event_types = set()
        for machine in event_counts.values():
            event_types.update(machine["counts"].keys())

        event_types = sorted(event_types)

        # Create figure
        fig, ax = plt.subplots(figsize=(12, 8))

        # Set width of bars
        bar_width = 0.8 / len(event_types)

        # Set positions of bars on X axis
        positions = np.arange(len(machines))

        # Set different colors for event types
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']

        # Plot bars
        for i, event_type in enumerate(event_types):
            counts = [event_counts[machine]["counts"].get(event_type, 0) for machine in machines]
            ax.bar(positions + i * bar_width, counts, bar_width,
                   label=event_type,
                   color=colors[i % len(colors)])

        # Add labels, title and custom x-axis tick labels
        ax.set_xlabel('Machine')
        ax.set_ylabel('Event Count')
        ax.set_title('Event Type Distribution Across Machines')
        ax.set_xticks(positions + bar_width * (len(event_types) - 1) / 2)
        ax.set_xticklabels([f'Machine {m}' for m in machines])
        ax.legend()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
        else:
            plt.show()

    def plot_clock_jump_histogram(self, save_path=None):
        """
        Plot histogram of clock jumps for each machine.

        Args:
            save_path (str, optional): Path to save the plot
        """
        jumps = self.find_clock_jumps(threshold=1)

        fig, axes = plt.subplots(len(jumps), 1, figsize=(12, 4 * len(jumps)))

        # Handle case where there's only one machine
        if len(jumps) == 1:
            axes = [axes]

        for i, (machine_id, machine_jumps) in enumerate(jumps.items()):
            ax = axes[i]

            if not machine_jumps:
                ax.text(0.5, 0.5, "No significant jumps detected",
                        horizontalalignment='center',
                        verticalalignment='center',
                        transform=ax.transAxes)
            else:
                jump_sizes = [jump["jump"] for jump in machine_jumps]
                ax.hist(jump_sizes, bins=range(min(jump_sizes), max(jump_sizes) + 2),
                        alpha=0.7, color='#1f77b4', edgecolor='black')

                # Calculate statistics
                mean_jump = np.mean(jump_sizes)
                median_jump = np.median(jump_sizes)
                max_jump = max(jump_sizes)

                # Add statistics to the plot
                ax.axvline(mean_jump, color='red', linestyle='dashed', linewidth=1, label=f'Mean: {mean_jump:.2f}')
                ax.axvline(median_jump, color='green', linestyle='dashed', linewidth=1, label=f'Median: {median_jump:.2f}')

            ax.set_xlabel('Jump Size')
            ax.set_ylabel('Frequency')
            ax.set_title(f'Clock Jumps for Machine {machine_id}')
            ax.grid(True, linestyle='--', alpha=0.7)

            if machine_jumps:
                ax.legend()

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
        else:
            plt.show()

    # def plot_message_flow(self, save_path=None):
    #     """
    #     Plot the flow of messages between machines as a directed graph.

    #     Args:
    #         save_path (str, optional): Path to save the plot
    #     """
    #     patterns = self.analyze_message_patterns()
    #     message_matrix = patterns["message_matrix"]

    #     # Create a figure
    #     plt.figure(figsize=(10, 8))

    #     # Define positions for nodes (machines) in a circle
    #     theta = np.linspace(0, 2 * np.pi, 3, endpoint=False)
    #     x = np.cos(theta)
    #     y = np.sin(theta)

    #     # Scale and adjust positions
    #     scale = 5
    #     x = x * scale
    #     y = y * scale

    #     # Plot machines as nodes
    #     node_size = 3000
    #     plt.scatter(x, y, s=node_size, c=['#1f77b4', '#ff7f0e', '#2ca02c'], zorder=10)

    #     # Label nodes
    #     for i in range(3):
    #         plt.text(x[i], y[i], f"M{i}", horizontalalignment='center',
    #                  verticalalignment='center', fontsize=12, color='white',
    #                  fontweight='bold', zorder=20)

    #     # Draw arrows for messages
    #     max_messages = np.max(message_matrix)
    #     for i in range(3):
    #         for j in range(3):
    #             if i != j and message_matrix[i][j] > 0:
    #                 # Calculate arrow width based on number of messages
    #                 width = 0.1 + 0.5 * (message_matrix[i][j] / max_messages)

    #                 # Calculate control points for curved arrows
    #                 # We'll use a quadratic Bezier curve
    #                 # Start and end points
    #                 start_x, start_y = x[i], y[i]
    #                 end_x, end_y = x[j], y[j]

    #                 # Middle point - perpendicular to the line connecting the nodes
    #                 dx, dy = end_x - start_x, end_y - start_y
    #                 length = np.sqrt(dx**2 + dy**2)

    #                 # Perpendicular direction
    #                 px, py = -dy/length, dx/length

    #                 # Control point location
    #                 curve_strength = 1.5  # Controls how curved the arrow is
    #                 control_x = (start_x + end_x) / 2 + curve_strength * px
    #                 control_y = (start_y + end_y) / 2 + curve_strength * py

    #                 # Create points for the curve
    #                 t = np.linspace(0, 1, 100)
    #                 curve_x = (1-t)**2 * start_x + 2*(1-t)*t * control_x + t**2 * end_x
    #                 curve_y = (1-t)**2 * start_y + 2*(1-t)*t * control_y + t**2 * end_y

    #                 # Plot the curve
    #                 plt.plot(curve_x, curve_y, '-', color='gray', alpha=0.7,
    #                          linewidth=width*2, zorder=1)

    #                 # Add an arrow at the end
    #                 arrow_length = 0.4
    #                 arrow_angle = np.arctan2(curve_y[-1] - curve_y[-2],
    #                                         curve_x[-1] - curve_x[-2])
    #                 dx = arrow_length * np.cos(arrow_angle)
    #                 dy = arrow_length * np.sin(arrow_angle)

    #                 # Draw the arrowhead
    #                 plt.arrow(curve_x[-2], curve_y[-2], dx, dy,
    #                           head_width=0.2 + 0.3*width, head_length=0.3 + 0.4*width,
    #                           fc='black', ec='black', zorder=5)

    #                 # Add count text
    #                 text_x = control_x + 0.3 * (end_x - start_x) / length
    #                 text_y = control_y + 0.3 * (end_y - start_y) / length
    #                 plt.text(text_x, text_y, str(int(message_matrix[i][j])),
    #                          fontsize=10, fontweight='bold',
    #                          bbox=dict(facecolor='white', alpha=0.7, edgecolor='none',
    #                                   boxstyle='round,pad=0.2'), zorder=15)

    #     plt.axis('equal')
    #     plt.axis('off')
    #     plt.title('Message Flow Between Machines', fontsize=14)

    #     if save_path:
    #         plt.savefig(save_path, dpi=300, bbox_inches='tight')
    #         plt.close()
    #     else:
    #         plt.show()

    def plot_clock_drift(self, save_path=None):
        """
        Plot the drift between logical clocks of different machines.

        Args:
            save_path (str, optional): Path to save the plot
        """
        plt.figure(figsize=(12, 8))

        # Combine data from all machines
        all_data = []
        for machine_id, log_df in self.logs.items():
            if log_df.empty:
                continue

            for _, row in log_df.iterrows():
                all_data.append({
                    'machine_id': machine_id,
                    'timestamp': row['timestamp'],
                    'seconds_from_start': row['seconds_from_start'],
                    'logical_clock': row['logical_clock']
                })

        # Convert to DataFrame for easier manipulation
        all_df = pd.DataFrame(all_data)

        # Sort by timestamp
        all_df = all_df.sort_values('timestamp')

        # Create scatter plot with logical clock values
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']  # Blue, orange, green

        for i in range(3):
            machine_data = all_df[all_df['machine_id'] == i]
            if not machine_data.empty:
                plt.scatter(machine_data['seconds_from_start'], machine_data['logical_clock'],
                           label=f'Machine {i}', color=colors[i], alpha=0.7, s=30)

        # Add polynomial trend lines to show drift
        for i in range(3):
            machine_data = all_df[all_df['machine_id'] == i]
            if len(machine_data) > 2:  # Need at least 3 points for quadratic fit
                x = machine_data['seconds_from_start']
                y = machine_data['logical_clock']

                # Use polynomial fit
                z = np.polyfit(x, y, 2)
                p = np.poly1d(z)

                # Get x range for the trend line
                x_trend = np.linspace(x.min(), x.max(), 100)

                # Plot the trend line
                plt.plot(x_trend, p(x_trend), '--', color=colors[i],
                        linewidth=2, alpha=0.8)

        plt.xlabel("Seconds from start")
        plt.ylabel("Logical Clock Value")
        plt.title("Logical Clock Drift Between Machines")
        plt.legend()
        plt.grid(True)

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
        else:
            plt.show()

    def generate_full_report(self, output_dir="./analysis_results"):
        """
        Generate a comprehensive analysis report with all metrics and plots.

        Args:
            output_dir (str): Directory to save results
        """
        # Create output directory if it doesn't exist
        os.makedirs(output_dir, exist_ok=True)

        # Clock rate comparison
        clock_rates = self.compare_clock_rates()

        # Event counts
        event_counts = self.get_event_counts()

        # Queue size analysis
        queue_stats = self.analyze_queue_sizes()

        # Clock jumps
        clock_jumps = self.find_clock_jumps(threshold=1)

        # Message patterns
        # message_patterns = self.analyze_message_patterns()

        # Generate plots
        print("Generating plots...")
        self.plot_logical_clocks(save_path=os.path.join(output_dir, "logical_clocks.png"))
        self.plot_queue_sizes(save_path=os.path.join(output_dir, "queue_sizes.png"))
        self.plot_event_distribution(save_path=os.path.join(output_dir, "event_distribution.png"))
        self.plot_clock_jump_histogram(save_path=os.path.join(output_dir, "clock_jumps.png"))
        # self.plot_message_flow(save_path=os.path.join(output_dir, "message_flow.png"))
        self.plot_clock_drift(save_path=os.path.join(output_dir, "clock_drift.png"))

        # Generate report text
        print("Generating report...")
        report = []
        report.append("# Lamport Clock Analysis Report\n")

        # Summary section
        report.append("## Executive Summary\n")
        report.append("This report analyzes the behavior of a distributed system using Lamport logical clocks. ")
        report.append("The system consists of three machines communicating via message passing, ")
        report.append("with each machine maintaining its own logical clock according to the Lamport algorithm.\n")

        # Add clock rate comparison
        report.append("## Clock Rate Comparison\n")
        for machine_id, stats in clock_rates.items():
            report.append(f"### Machine {machine_id}\n")
            report.append(f"- Start Time: {stats['start_time']}")
            report.append(f"- End Time: {stats['end_time']}")
            report.append(f"- Time Span: {stats['time_span_seconds']:.2f} seconds")
            report.append(f"- Start Clock: {stats['start_clock']}")
            report.append(f"- End Clock: {stats['end_clock']}")
            report.append(f"- Clock Range: {stats['clock_range']}")
            report.append(f"- Clock Rate: {stats['clock_rate']:.2f} ticks/second\n")

        # Add event counts
        report.append("## Event Count Analysis\n")
        for machine_id, counts in event_counts.items():
            report.append(f"### Machine {machine_id}\n")
            report.append(f"- Total Events: {counts['total']}")
            for event, count in counts['counts'].items():
                report.append(f"- {event}: {count} ({counts['percentages'][event]:.2f}%)")
            report.append("")

        # Add queue size analysis
        report.append("## Queue Size Analysis\n")
        for machine_id, stats in queue_stats.items():
            report.append(f"### Machine {machine_id}\n")
            report.append(f"- Maximum Queue Size: {stats['max']}")
            report.append(f"- Minimum Queue Size: {stats['min']}")
            report.append(f"- Mean Queue Size: {stats['mean']:.2f}")
            report.append(f"- Median Queue Size: {stats['median']}")
            report.append(f"- Final Queue Size: {stats['end_value']}")
            report.append("\nAverage Queue Size by Event Type:")
            for event, avg in stats['by_event_type'].items():
                report.append(f"- {event}: {avg:.2f}")
            report.append("")

        # Add clock jump analysis
        report.append("## Clock Jump Analysis\n")
        for machine_id, jumps in clock_jumps.items():
            report.append(f"### Machine {machine_id}\n")
            if jumps:
                report.append(f"- Total Jumps: {len(jumps)}")
                report.append("\nTop 5 largest jumps:")
                for jump in sorted(jumps, key=lambda x: x['jump'], reverse=True)[:5]:
                    report.append(f"- Jump of {jump['jump']} at {jump['to_time']} ({jump['from_clock']} → {jump['to_clock']}) during {jump['event_type']}")
            else:
                report.append("No significant clock jumps detected.\n")
            report.append("")

        # # Add message pattern analysis
        # report.append("## Message Pattern Analysis\n")
        # # message_matrix = message_patterns["message_matrix"]
        # report.append("### Message Count Matrix\n")
        # report.append("From Machine (row) to Machine (column):\n")
        # report.append("```")
        # report.append("    | M0  | M1  | M2  |")
        # report.append("----|-----|-----|-----|")
        # for i in range(3):
        #     row = f"M{i} |"
        #     for j in range(3):
        #         row += f" {int(message_matrix[i][j]):3d} |"
        #     report.append(row)
        # report.append("```\n")

        # # Add total sent and received by each machine
        # report.append("### Total Messages\n")
        # for i in range(3):
        #     sent = sum(message_matrix[i])
        #     received = sum(message_matrix[:, i])
        #     report.append(f"- Machine {i}: Sent {int(sent)} messages, Received {int(received)} messages")
        # report.append("")

        # Add conclusions section
        report.append("## Conclusions\n")

        # Find machine with highest clock rate
        max_rate_machine = max(clock_rates.items(), key=lambda x: x[1]['clock_rate'])[0]
        max_rate = clock_rates[max_rate_machine]['clock_rate']

        # Find machine with most events
        most_events_machine = max(event_counts.items(), key=lambda x: x[1]['total'])[0]
        most_events = event_counts[most_events_machine]['total']

        # Find machine with largest queue
        largest_queue_machine = max(queue_stats.items(), key=lambda x: x[1]['max'])[0]
        largest_queue = queue_stats[largest_queue_machine]['max']

        report.append(f"1. **Clock Rate**: Machine {max_rate_machine} had the highest logical clock rate at {max_rate:.2f} ticks/second.")
        report.append(f"2. **Event Volume**: Machine {most_events_machine} processed the most events ({most_events}).")
        report.append(f"3. **Queue Size**: Machine {largest_queue_machine} had the largest queue size ({largest_queue}).")

        # # Message distribution
        # report.append("4. **Message Distribution**:")
        # total_messages = np.sum(message_matrix)
        # if total_messages > 0:
        #     for i in range(3):
        #         for j in range(3):
        #             if i != j and message_matrix[i][j] > 0:
        #                 percentage = (message_matrix[i][j] / total_messages) * 100
        #                 report.append(f"   - {percentage:.1f}% of messages were sent from Machine {i} to Machine {j}")

        # Clock jumps
        total_jumps = sum(len(jumps) for jumps in clock_jumps.values())
        report.append(f"5. **Clock Jumps**: A total of {total_jumps} significant clock jumps were detected across all machines.")

        # Add observations about Lamport clock behavior
        report.append("\n### Observations on Lamport Clock Behavior\n")
        report.append("- The logical clocks advance at different rates due to the different execution speeds of the machines.")
        report.append("- Message receipt causes clock jumps when the sender's clock is ahead of the receiver's clock.")
        report.append("- The queue sizes fluctuate based on the balance between incoming messages and processing rate.")
        report.append("- Internal events cause the logical clock to advance by exactly 1, while receive events may cause larger jumps.")

        # Write report to file
        with open(os.path.join(output_dir, "analysis_report.md"), "w") as f:
            f.write("\n".join(report))

        print(f"Analysis complete. Results saved to {output_dir}")
        return os.path.join(output_dir, "analysis_report.md")